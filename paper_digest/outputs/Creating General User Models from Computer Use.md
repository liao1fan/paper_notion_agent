# Creating General User Models from Computer Use

## 📋 基本信息
- **作者**: Omar Shaikh, Shardul Sapkota, Shan Rizvi, Eric Horvitz, Joon Sung Park, Diyi Yang, Michael S. Bernstein  
- **发表时间**: 2025-09-21  
- **来源**: The 38th Annual ACM Symposium on User Interface Software and Technology (UIST ’25)  
- **论文链接**: https://doi.org/10.1145/3746059.3747722 ; arXiv: https://arxiv.org/abs/2505.10831v3  
- **标签**: 人机交互 (HCI), 用户建模, 多模态模型, 交互系统, 主动助理

---

## 📝 摘要 (Abstract)
本文提出通用用户模型（General User Model, GUM）架构：通过观察用户在计算机上的任何非结构化交互（例如截图），利用大规模多模态模型将观察转为带置信度的自然语言命题（propositions），以表示用户的行为、知识、信念和偏好。GUM包含推断（Propose）、检索（Retrieve）与修正（Revise）模块，并配备基于“情境完整性”的审核（Audit）模块以保护隐私。作者进一步实现了基于 GUM 的主动助理 Gumbo，可发现并在合适时机执行对用户有价值的建议。技术评估与小规模用户研究表明：GUM 在置信度上校准良好、推断准确，并能支持能带来实用价值的主动系统应用。

---

## 🎯 研究背景与动机 (Background & Motivation)

### 问题背景
- 长期的 HCI 愿景（如 Weiser 的 ubiquitous/calm computing、interface agents）希望系统能够理解并主动帮助用户——但现有用户模型通常碎片化、针对特定应用，缺乏跨上下文、跨应用的灵活推理能力。
- 现有方法多集中于单一域（音乐偏好、单 app 行为等）或依赖受限传感器/结构化数据，难以实现“统一、可推理的用户表示”。

### 研究动机
- 利用近年来多模态大模型（VLMs/LLMs）对非结构化输入（如截图、通知、文件活动）强大的理解能力，探索一种通用的、可持续更新、跨应用可复用的用户表征方式，以支撑多种 HCI 应用（提示 LLM、通知管理、主动助理等）。

### 核心观点
- 以自然语言命题（带置信度）为基本单元构建通用用户模型（GUM），通过不断观察、检索和修正实现跨时间、跨应用的用户理解，且把隐私控制作为核心模块嵌入（Audit 模块）。

---

## 🔍 现有方法及其局限 (Related Work & Limitations)

### 现有解决方案
1. **对话历史/长记忆**：保存与模型互动的历史作为个人上下文（但通常只限于与该模型的对话）。  
2. **RAG（检索增强生成）与记忆库**：基于结构化/半结构化存储检索上下文（如 OmniQuery），通常依赖预定义数据源或专门的特征抽取。  
3. **特定应用/传感器驱动的上下文感知系统**：围绕定制传感器或固定数据流构建上下文（例如日历 + 邮箱分析），缺乏对任意非结构化输入的泛化能力。  
4. **混合主动交互与代理系统**：早期 interface agents、混合主导模型，通常需要大量手工工程与域特定数据。

### 存在的问题
- 缺乏跨应用的统一表示与推理能力（碎片化）。  
- 需要为每个新传感器/应用工程化大量处理流程。  
- 与用户建立“共同语境”（common ground）通常被动发生或依赖用户明确输入；模型往往过于健谈或误判上下文。  
- 隐私与意外敏感信息暴露风险高，缺乏情境化的自动过滤机制。

---

## 💡 本文方法 (Proposed Method)

### 核心思想
- 用“自然语言命题 + 置信度”作为通用、可解释、可检索的用户表征单位；从任意可被多模态模型处理的非结构化观察中生成并持续修正这些命题，供应用实时查询和决策。

### 技术路线
整体架构包含：Observers（监听各种非结构化输入，例如屏幕截图、通知、文件系统事件）→ Audit（基于情境完整性过滤敏感观察）→ Propose（从观察生成带置信度的命题并给出推理理由与衰减率）→ Store（命题库）→ Retrieve（基于查询检索相关命题）→ Revise（随着新观察更新命题并调整置信度）。上层应用（如 Gumbo）基于 GUM 进行建议生成、优先级评估与执行。

（图示见论文 Fig.4，流程为 Observe → Audit → Propose → Retrieve → Revise → 应用/反馈）

### 关键创新点
1. **通用命题表示**：用自然语言命题（附带置信度、衰减分数与推理证据）作为统一用户模型单元，便于跨应用共享与解释。  
2. **多模态、任意输入到用户模型的路径**：系统设计为接受任意 VLM/LLM 能处理的输入（截图、文本、通知、传感器数据等），实现对非结构化上下文的持续建模。  
3. **情境完整性驱动的隐私审核（Audit）**：使用 GUM 自身检索到的命题来判断新观察是否属于用户期望被捕捉/存储的上下文，从而过滤敏感数据。  
4. **基于 GUM 的主动助理（Gumbo）**：演示如何用 GUM 发现、评估（基于混合主动性预期效用计算）并在安全范围内执行建议，形成可用的主动服务。

---

## ⚙️ 方法实现细节 (Implementation Details)

### 算法/模型设计
- 观察处理（Observers）：实现了 Screen Observer（监听键鼠 I/O，截图并用 VLM 转录与生成行为描述）、Notification Observer、以及可扩展的其他观察器（可接入音频、健康数据等）。  
- 审核（Audit）：基于 Nissenbaum 的情境完整性，检索 GUM 内既有命题并回答标准问题（如“当前披露是否为新信息？信息类型？接收者？”）来决定是否阻止将观察录入 GUM。  
- Propose：对每个通过审核的观察，生成推理（reasoning trace）、命题文本、置信度评分与衰减率（decay），并将支持证据（grounding：相关观察）一并记录。推理与命题由指令式提示调用大型模型生成（论文实现中采用 Llama 3.3 70B）。  
- Retrieve & Revise：基于语义检索（使用命题文本与元数据）返回相关命题；在新证据到来时，Revise 使用检索到的上下文重新评估并更新既有命题的置信度/文本/推理。  
- Gumbo（示例应用）：定期检索相关命题集合 G，基于这些命题用 LLM 生成候选建议 τ_i 并为建议估计 P(τ_i|G)。然后用混合主动性（expected utility）框架估算是否中断用户（E[U_interrupt] vs E[U_no_interrupt]），若可自动安全执行则调用工具（Google/Gemini 搜索、文件搜索、Operator API 等）在沙箱内执行并向用户展示结果；用户反馈再次作为观察注入 GUM。

### 技术细节
- **底层模型**: 视觉-语言模型用于截图理解（Qwen 2.5 VL 72B）；语言模型用于推理、生成命题与评分（Llama 3.3 70B 在作者实现中用于私有推理；兼容遵循 OpenAI ChatCompletions API 的模型）。  
- **命题元数据**: 每条命题包含文本、置信度（confidence）、衰减分数（decay，0-1）、支持观察的引用、生成的推理轨迹与时间戳。论文在不同处对置信度刻度描述存在表述差异（在方法里说 0-1，但评估节提到“confidence = 10”），实现时应统一尺度。  
- **输入/输出**:  
  - 输入：任意可由模型编码的非结构化观测（screenshots, notifications, file events, transcripts 等）。  
  - 输出：命题列表（文本＋置信度＋元数据）；应用查询接口提供按相关性/多样性/时间窗口检索的能力。

### 实现要点
- 把“推理轨迹”作为可审计证据，以增加可解释性与用户可编辑性。  
- 将所有命题与观测保存在本地（强调隐私和用户控制），且对外部工具调用默认禁用，需要用户明确授权。  
- 借助 GUM 自身产生的命题来辅助 Audit（形成闭环），允许系统学习用户关于数据分享的规范与偏好。  
- 在 Gumbo 中，使用基于代价与收益的公式（Horvitz 风格）结合置信度来决定是否中断用户；同时加入简单的 rate-limiting（token bucket）防止过度打扰。

---

## 📊 实验与结果 (Experiments & Results)

### 实验设置
- **两类评估**：  
  1. 技术/准确性评估（离线）：在邮件交互数据上训练/评估 GUM 命题的准确性与置信度校准。  
  2. 纵向用户部署（在线）：将 Gumbo 部署给真实用户连续观测其屏幕（截图）并衡量建议的有用性与执行效果。  
- **参与者**：技术评估 N = 18（判断命题准确性）；纵向部署 N = 5，运行 5 天。  
- **模型与工具**：Qwen 2.5 VL（截图理解）、Llama 3.3 70B（命题生成/评估/建议生成）。  
- **评价指标**：命题准确率、置信度校准（高置信度命题的准确率）、用户对 Gumbo 建议的主观有用性与接受情况、是否希望继续使用系统。

### 主要结果
- 命题总体准确率：平均约 76.15%（含低置信度命题）。  
- 高置信度命题表现：论文报告“Highly confident propositions (confidence = 10) were rated 100% accurate”。（注：论文主体对置信度量表在不同段落表述不一；实现应明确量化刻度）  
- 消融研究（ablation）显示：Propose / Retrieve / Revise / Audit 等组件均对整体准确性至关重要。  
- Gumbo 纵向部署（N=5, 5天）：系统发现并自动/半自动执行了若干对用户有实用价值的建议；两名参与者对系统价值感受高，愿意继续运行系统。其他参与者也报告了有意义的建议（例如个性化搬家计划、整理邮件档案、学术写作建议等）。  
- 隐私与边界：评估中暴露出隐私敏感性与“过度坦率的命题”问题（系统有时会生成太直接或超出用户期望的命题），并指出需要更精细的审计/控制。

（可展示的关键数据表）
| 实验类型 | 参与者数 | 指标 | 结果 |
|---|---:|---:|---:|
| 命题准确性评估 | 18 | 平均准确率 | 76.15% |
| 高置信度命题 | — | 高置信度命题准确率 | 100%（论文报告） |
| 纵向部署 Gumbo | 5 | 用户愿意继续使用者数量 | 2 |

### 分析与讨论
- GUM 在将非结构化观察转为自然语言命题并给出置信度方面表现出较好的校准（尤其在高置信度命题上准确可靠），这支持其作为跨应用上下文源用于给 LLM 和应用提供共同语境。  
- Gumbo 能生成并执行有价值的建议，证明 GUM 能够作为主动助理的知识/推理基础。  
- 评估也暴露出实际部署的挑战：隐私敏感信息过滤、命题的过度外推（over-candidness）、置信度刻度与用户期望之间的错配以及计算/资源成本问题。

---

## ⚠️ 局限性 (Limitations)
1. **隐私风险与审核难题**：尽管内置 Audit 模块，但自动判断何为“用户期望被捕捉”的信息仍具挑战，错误过滤或误放行均有可能发生。  
2. **对模型与提示工程的依赖**：实现依赖于大型多模态/语言模型（论文实现使用 Qwen、Llama），这些模型在资源、准确性和偏差方面各有限制，且部分为闭源/需云推理时带来额外隐私风险。  
3. **置信度刻度与表述不一致**：论文中在不同段落对置信度刻度的描述存在不一致（0-1 vs 0-10），提示对置信度归一化与校准仍需明确实现与用户可理解化。  
4. **有限规模的用户评估**：技术评估与纵向部署样本量较小（N=18、N=5），尚不足以证明在不同人群与复杂长期使用场景下的稳健性。  
5. **计算与能耗成本**：持续捕获截图与多模态推理对端设备或云服务造成显著计算负担，影响可部署性。  
6. **可能产生过度主动或不受欢迎的行为**：Gumbo 的主动执行若设定不当，可能造成错误执行或用户反感（尤其当建议有副作用或涉及财务/身份敏感操作时）。

---

## 🔮 未来方向 (Future Work)
1. **本地化与高效推理**：推动更小、更高效的多模态模型在本地设备上运行，以减少隐私泄露与云成本。  
2. **更精细的隐私策略学习**：改进 Audit 模块，支持可解释的用户可控隐私策略（用户能以更直观的方式定义/调整何种信息可被建模）。  
3. **大规模与多样化用户研究**：在更多使用场景、文化/职业群体中评估 GUM 的可靠性、用户接受度与长期效益。  
4. **跨设备与跨人合作建模**：探索在用户多人协作情境中如何构建与同步 GUM（考虑他人隐私与协作语境）。  
5. **更强的置信度校准机制**：统一置信度刻度并结合在线校准方法，使置信评分对用户更有可解释性与可靠性。  
6. **扩展工具链与安全执行策略**：在 Gumbo 中为自动执行引入更安全的沙箱与回滚机制、以及更复杂的风险评估模块。

---

## 💭 个人思考 (Personal Notes)
- GUM 将“观察→自然语言命题→置信度”作为通用接口，是一个非常直观也具实践意义的设计：便于解释、检索、编辑，也能无缝地为 LLM 提供上下文。但要在现实部署中被用户接受，关键在于隐私控制的透明性与可操作性（用户能否方便地查看/删除/纠正命题）。  
- Audit 模块把隐私判断回归到上下文规范是恰当的方向，但其本身依赖模型的推断，形成了“用模型判断模型是否可查看数据”的闭环，这需要额外的审计与可解释性保障以避免循环放大错误。  
- Gumbo 的混合主动性决策（基于期望效用）把经典理论工程化，这是很有价值的尝试；但效用/成本的量化很大程度依赖 prompt 提示与模型估计，长期运行下需更稳健的用户反馈回路与学习机制。  
- 伦理与法务层面：持续采集屏幕内容在不同法域/共享设备上会触及合规问题（隐私、数据保护），产品化前需制定明确策略与合规流程。

---

## 📚 参考资料 (References)
- 论文原文（UIST’25 / arXiv）: https://doi.org/10.1145/3746059.3747722 , https://arxiv.org/abs/2505.10831v3  
- 代码/演示: 论文提到 demo 与开源包（https://generalusermodels.github.io），建议查看作者发布页获取具体仓库（若已公开）。  
- 相关背景参考（论文中引用的经典工作）：Weiser 的 Calm/ ubiquitous computing、Maes 的 interface agents、Nissenbaum 的 Contextual Integrity 等。

---

整理时间: 2025-10-21  
置信度: 0.90（基于论文 PDF 主体内容提取；部分数值/刻度在论文内部存在表述不一致，已在正文注明）