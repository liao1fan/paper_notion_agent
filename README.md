# Paper Agent Scheduler

An autonomous AI agent that fetches research paper information from Xiaohongshu posts, extracts and summarizes content through conversational interaction, and organizes it into a Notion knowledge base.

## Project Status

**Current Phase**: Phase 3 Complete âœ… - MVP Ready!

- âœ… Phase 1: Setup (Project structure, dependencies, configuration)
- âœ… Phase 2: Foundational (Models, utilities, database, agent core)
- âœ… Phase 3: User Story 1 - Manual Post Processing (MVPåŠŸèƒ½å®Œæˆï¼)
- â³ Phase 4: User Story 2 - Scheduled Automation
- â³ Phase 5: User Story 3 - Multi-turn Conversation Context

## Features

### User Story 1 - Manual Post Processing (P1) ğŸ¯ MVP âœ…
- âœ… Fetch Xiaohongshu posts by URL
- âœ… Extract paper metadata (title, authors, summary, tags, PDF links)
- âœ… Present extracted information for user review
- âœ… Save approved content to Notion database
- âœ… Pattern-based extraction with LLM fallback
- âœ… Confidence scoring for extraction quality
- âœ… Duplicate detection via processing records

### User Story 2 - Scheduled Automation (P2)
- Configure recurring schedules via natural language
- Auto-fetch new posts from specified bloggers
- Batch processing with duplicate detection
- Comprehensive error logging and retry policies

### User Story 3 - Multi-turn Conversation (P3)
- Maintain context across multiple turns
- Handle clarifications and refinements
- Natural language interaction
- Implicit action detection

## Technical Stack

- **Runtime**: Python 3.11+
- **AI Framework**: OpenAI Agents SDK
- **LLM**: OpenAI GPT-4o-mini (via custom proxy)
- **Storage**: SQLite (local state), Notion API (paper content)
- **Scheduling**: APScheduler
- **HTTP Client**: httpx
- **Data Validation**: Pydantic v2
- **Logging**: structlog (JSON format)

## Project Structure

```
spec-paper-notion-agent/
â”œâ”€â”€ .env                    # Configuration (see .env.example)
â”œâ”€â”€ .env.example            # Configuration template
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py            # Application entry point
â”‚   â”œâ”€â”€ agent/             # Agent core and tools
â”‚   â”‚   â”œâ”€â”€ core.py        # Agent initialization
â”‚   â”‚   â”œâ”€â”€ tools.py       # Agent tool definitions
â”‚   â”‚   â””â”€â”€ callbacks.py   # Scheduled execution callbacks
â”‚   â”œâ”€â”€ models/            # Data models (Pydantic)
â”‚   â”‚   â”œâ”€â”€ config.py      # Environment configuration
â”‚   â”‚   â”œâ”€â”€ post.py        # Xiaohongshu post entity
â”‚   â”‚   â”œâ”€â”€ extraction.py  # Paper metadata entity
â”‚   â”‚   â”œâ”€â”€ task.py        # Scheduled task entity
â”‚   â”‚   â”œâ”€â”€ record.py      # Processing record entity
â”‚   â”‚   â”œâ”€â”€ notion_entry.py # Notion database mapping
â”‚   â”‚   â””â”€â”€ context.py     # Conversation context
â”‚   â”œâ”€â”€ services/          # External integrations
â”‚   â”‚   â”œâ”€â”€ xiaohongshu.py # Post fetching (Phase 3)
â”‚   â”‚   â”œâ”€â”€ notion.py      # Notion API client (Phase 3)
â”‚   â”‚   â”œâ”€â”€ processor.py   # Content extraction (Phase 3)
â”‚   â”‚   â””â”€â”€ scheduler.py   # Task scheduling (Phase 4)
â”‚   â”œâ”€â”€ storage/           # Database operations
â”‚   â”‚   â”œâ”€â”€ database.py    # SQLite operations
â”‚   â”‚   â””â”€â”€ migrations/    # Schema migrations
â”‚   â””â”€â”€ utils/             # Utilities
â”‚       â”œâ”€â”€ logger.py      # Structured logging
â”‚       â”œâ”€â”€ retry.py       # Exponential backoff
â”‚       â””â”€â”€ validators.py  # Path and data validation
â”œâ”€â”€ data/                  # SQLite databases (gitignored)
â”œâ”€â”€ logs/                  # Execution logs (gitignored)
â””â”€â”€ specs/                 # Feature specifications
    â””â”€â”€ 001-paper-agent-scheduler/
        â”œâ”€â”€ spec.md        # Feature specification
        â”œâ”€â”€ plan.md        # Implementation plan
        â”œâ”€â”€ tasks.md       # Task breakdown (80 tasks)
        â”œâ”€â”€ data-model.md  # Entity definitions
        â””â”€â”€ contracts/     # API contracts
```

## Setup

### 1. Prerequisites

- Python 3.11 or higher
- pip and venv

### 2. Installation

```bash
# Create virtual environment
python3 -m venv .venv

# Activate virtual environment
source .venv/bin/activate  # On macOS/Linux
# or
.venv\Scripts\activate  # On Windows

# Install dependencies
pip install -r requirements.txt
```

### 3. Configuration

Copy `.env.example` to `.env` and fill in your credentials:

```bash
cp .env.example .env
```

Required environment variables:
- `OPENAI_BASE_URL`: OpenAI API endpoint
- `OPENAI_API_KEY`: OpenAI API key
- `XHS_COOKIES`: Xiaohongshu browser session cookies
- `NOTION_TOKEN`: Notion integration secret
- `NOTION_DATABASE_ID`: Target Notion database ID

### 4. Run

```bash
# Activate virtual environment (if not already activated)
source .venv/bin/activate

# Run the application
python -m src.main
```

## ä½¿ç”¨ç¤ºä¾‹

### åŸºæœ¬å¯¹è¯æµç¨‹

```
æ‚¨: https://www.xiaohongshu.com/explore/xxxxx

åŠ©æ‰‹: æˆ‘æ¥å¸®æ‚¨è·å–è¿™ä¸ªå¸–å­çš„å†…å®¹...
[Agent è‡ªåŠ¨è°ƒç”¨ fetch_xiaohongshu_post å·¥å…·]

åŠ©æ‰‹: å¸–å­å†…å®¹è·å–æˆåŠŸï¼ç°åœ¨æˆ‘æ¥æå–è®ºæ–‡ä¿¡æ¯...
[Agent è‡ªåŠ¨è°ƒç”¨ extract_paper_info å·¥å…·]

åŠ©æ‰‹: è®ºæ–‡ä¿¡æ¯æå–å®Œæˆï¼ä»¥ä¸‹æ˜¯æå–çš„ä¿¡æ¯ï¼š

æ ‡é¢˜: Attention Is All You Need
ä½œè€…: Ashish Vaswani, Noam Shazeer, Niki Parmar
æ‘˜è¦: We propose a new architecture...
æ ‡ç­¾: transformer, attention, nlp
ç½®ä¿¡åº¦: 0.95

è¯·ç¡®è®¤ä¿¡æ¯æ˜¯å¦æ­£ç¡®ï¼Ÿå¦‚æœæ­£ç¡®ï¼Œæˆ‘å°†ä¿å­˜åˆ° Notionã€‚

æ‚¨: ç¡®è®¤

åŠ©æ‰‹: å¥½çš„ï¼Œæˆ‘ç°åœ¨ä¿å­˜åˆ° Notion...
[Agent è‡ªåŠ¨è°ƒç”¨ save_to_notion å·¥å…·]

åŠ©æ‰‹: âœ“ è®ºæ–‡ã€ŠAttention Is All You Needã€‹å·²æˆåŠŸä¿å­˜åˆ° Notion çŸ¥è¯†åº“ï¼
Notion é¡µé¢é“¾æ¥: https://notion.so/xxxxx
```

### å¯ç”¨å‘½ä»¤

- å‘é€å°çº¢ä¹¦å¸–å­ URL å¼€å§‹å¤„ç†
- `help` - æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
- `exit` æˆ– `quit` - é€€å‡ºç¨‹åº

## Development Status

### Completed (Phase 3 - MVPå®Œæˆï¼) âœ…

âœ… **Setup & Configuration**
- Project directory structure
- Environment configuration with validation
- Dependency management
- Git repository initialized

âœ… **Data Models** (7 entities with Pydantic validation)
- `AppConfig`: Environment variable loading with validation
- `Post`: Xiaohongshu post representation
- `PaperExtraction`: Extracted paper metadata
- `ScheduledTask`: Recurring automation jobs
- `ProcessingRecord`: Duplicate detection
- `NotionEntry`: Notion database mapping
- `ConversationContext`: Multi-turn state management

âœ… **Utilities**
- Structured logging (JSON format, file rotation ready)
- Exponential backoff retry decorator
- Path validation for directory confinement
- URL and data validators

âœ… **Storage Layer**
- SQLite database initialization
- Schema for processing_records and scheduled_tasks
- CRUD operations with async support
- Migration framework ready

âœ… **Agent Core**
- OpenAI client configuration with custom base URL
- Agent initialization with instructions
- AppContext for shared resources
- Placeholder for tools and callbacks

âœ… **Testing**
- Environment validation working
- Database initialization verified
- Agent creation successful
- Structured logging functional

âœ… **Xiaohongshu Client** (T021-T025)
- HTTP client with cookie-based authentication
- Rate limiting (10 req/min configurable)
- HTML parsing and JSON extraction from `window.__INITIAL_STATE__`
- Comprehensive error handling (AuthenticationError, PostNotFoundError, RateLimitError, FetchError)
- Cookie validation method

âœ… **Notion Client** (T026-T029)
- Async Notion API wrapper with notion-client
- Page creation with exponential backoff retry
- Connection validation and schema validation
- Rate limit compliance with semaphore-controlled concurrency
- Batch creation support

âœ… **Paper Processor** (T030-T034)
- Pattern-based extraction using regex patterns
- LLM fallback extraction with GPT-4o-mini
- Confidence scoring algorithm
- Hybrid extraction merging pattern and LLM results
- Processing record tracking in SQLite

âœ… **Agent Tools** (T035-T037)
- `fetch_xiaohongshu_post` - è·å–å°çº¢ä¹¦å¸–å­å†…å®¹
- `extract_paper_info` - æå–è®ºæ–‡ä¿¡æ¯ï¼ˆæ”¯æŒ LLMï¼‰
- `save_to_notion` - ä¿å­˜åˆ° Notion çŸ¥è¯†åº“
- All tools with Chinese docstrings and user-friendly error messages

âœ… **Conversation Loop** (T038-T040)
- Runner initialization with OpenAI client
- Interactive console interface with welcome message
- User input/output handling
- Context management across conversation turns
- Error handling and recovery
- Help and exit commands

### Next Steps (Phase 4 & 5)

**Phase 4: Scheduled Automation (P2)**
- APScheduler integration for recurring tasks
- Natural language to cron expression parsing
- Batch processing with duplicate detection
- Task management (create, list, update, delete)
- Scheduled execution callbacks

**Phase 5: Multi-turn Conversation Context (P3)**
- Advanced context retention across multiple turns
- Implicit action detection
- Conversation history replay
- Refinement and clarification handling

## Architecture Principles

From [constitution.md](.specify/memory/constitution.md):

1. **Agent-First Architecture**: OpenAI Agents SDK as core runtime
2. **Scheduled Automation** (NON-NEGOTIABLE): All automation via APScheduler
3. **Directory Confinement**: All operations within project directory
4. **Notion as Single Source of Truth**: No separate database for paper content
5. **Observability & Debugging**: Structured logging for all executions

## License

See project license.

## Documentation

- **Specification**: [specs/001-paper-agent-scheduler/spec.md](specs/001-paper-agent-scheduler/spec.md)
- **Implementation Plan**: [specs/001-paper-agent-scheduler/plan.md](specs/001-paper-agent-scheduler/plan.md)
- **Task Breakdown**: [specs/001-paper-agent-scheduler/tasks.md](specs/001-paper-agent-scheduler/tasks.md)
- **Data Model**: [specs/001-paper-agent-scheduler/data-model.md](specs/001-paper-agent-scheduler/data-model.md)
- **Constitution**: [.specify/memory/constitution.md](.specify/memory/constitution.md)
